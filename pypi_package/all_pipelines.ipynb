{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Welcome to the Docs Notebook for `the-fairly-project` PyPI Package!!\n",
        "\n",
        "### This notebook will walk you through all of the bias analysis pipelines built-in to our Python Package.\n",
        "\n",
        "---\n",
        "\n",
        "[The Fair-ly Project](https://ethical-spectacle-research.gitbook.io/fair-ly) is maintained by ML researchers to keep a updated directory of bias detection research and implementations anyone can use. Like the python package in this notebook :).\n",
        "\n",
        "[üìë Docs]((https://ethical-spectacle-research.gitbook.io/fair-ly) | [üêç PyPI Page](https://pypi.org/project/the-fairly-project/)"
      ],
      "metadata": {
        "id": "44APNIMqo2Ux"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OreXqkscoyTq"
      },
      "outputs": [],
      "source": [
        "!pip install the-fairly-project # latest is 0.5 (as of Oct 29, 2024)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `TextAnalyzer` Pipeline\n",
        "\n",
        "[Full TextAnalyzer Docs](https://ethical-spectacle-research.gitbook.io/fair-ly/toolkit/python-package/textanalyzer-pipeline)"
      ],
      "metadata": {
        "id": "9dRUyksCCN0r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import the `TextAnalyzer` Pipeline"
      ],
      "metadata": {
        "id": "7Ij5eaUEJN_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fairly import TextAnalyzer"
      ],
      "metadata": {
        "id": "z987AQJaJKk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize the `TextAnalyzer` Pipeline\n",
        "\n",
        "You can customize each pipeline with the kwargs during init. You do this by specifying tasks, and fairly only initializes the models needed for your task, here are the options:\n",
        "\n",
        "\n",
        "\n",
        "*   **`bias`**: `None` (default) or `\"ternary\"` (to do: binary)\n",
        "*   **`classes`**: `False` (default) or `True`\n",
        "*   **`top_k_classes`**: `3` (default), can be `1`-`11`.\n",
        "*   **`ner`**: `None` (default) or `\"gus\"` (to do: general bias token classifier)\n",
        "\n",
        "\n",
        "The full descriptions of kwargs are [here](https://ethical-spectacle-research.gitbook.io/fair-ly/toolkit/python-package/textanalyzer-pipeline)."
      ],
      "metadata": {
        "id": "P0RJ020TJbzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_pipeline = TextAnalyzer(\n",
        "    bias=\"ternary\", # defaults to None\n",
        "    classes=True, # defaults to False\n",
        "    top_k_classes=3, # defaults to 3\n",
        "    ner=\"gus\" # defaults to None\n",
        "    )"
      ],
      "metadata": {
        "id": "IaLQj0zuq4gB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run Bias Analysis on a Sentence\n",
        "\n",
        "Pass in a string to the `.analyze` method\n",
        "\n",
        "*Note: the max token length for all of the models' input text is 512. The models are trained and evaluated on 1-2 sentence text sequences. Exceeding the maximum length will result in truncation to 512 tokens.*"
      ],
      "metadata": {
        "id": "7tqeIauILd6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = text_pipeline.analyze(\"Data scientists are so annoying\")"
      ],
      "metadata": {
        "id": "6fPyxYoZrLH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example Output"
      ],
      "metadata": {
        "id": "RH8knbKJLjyl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json # output is in json\n",
        "result = json.dumps(result, indent=2) # just formatting for you ;)\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJKKQVCrLofQ",
        "outputId": "5fa2037b-f165-4b86-8c07-54dfed764ab7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"text\": {\n",
            "    \"text\": \"Data scientists are so annoying\",\n",
            "    \"label\": \"Highly Biased\",\n",
            "    \"score\": 0.7465522885322571,\n",
            "    \"aspects\": {\n",
            "      \"educational\": 0.9512362480163574,\n",
            "      \"gender\": 0.011456429027020931,\n",
            "      \"socioeconomic\": 0.006828173063695431\n",
            "    }\n",
            "  },\n",
            "  \"ner\": [\n",
            "    {\n",
            "      \"token\": \"data\",\n",
            "      \"labels\": [\n",
            "        \"B-STEREO\",\n",
            "        \"B-GEN\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"token\": \"scientists\",\n",
            "      \"labels\": [\n",
            "        \"I-STEREO\",\n",
            "        \"B-GEN\",\n",
            "        \"I-GEN\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"token\": \"are\",\n",
            "      \"labels\": [\n",
            "        \"I-STEREO\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"token\": \"so\",\n",
            "      \"labels\": [\n",
            "        \"I-STEREO\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"token\": \"annoying\",\n",
            "      \"labels\": [\n",
            "        \"I-STEREO\",\n",
            "        \"B-UNFAIR\"\n",
            "      ]\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `MultimodalAnalyzer` Pipeline\n",
        "\n",
        "[Full Multimodal Pipeline Docs](https://ethical-spectacle-research.gitbook.io/fair-ly/toolkit/python-package/multimodalanalyzer-pipeline)"
      ],
      "metadata": {
        "id": "I8vdcSpoM6-6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import the `MultimodalAnalyzer` Pipeline"
      ],
      "metadata": {
        "id": "kWtNTmbiN0ss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fairly import MultimodalAnalyzer"
      ],
      "metadata": {
        "id": "I71JupiUNznG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize the `MultimodalAnalyzer` Pipeline"
      ],
      "metadata": {
        "id": "XEBnQnNBOFHk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "multimodal_pipeline = MultimodalAnalyzer()"
      ],
      "metadata": {
        "id": "CwLHYkLHORdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Input formatting\n",
        "\n",
        "*   **Image**: Must be in PIL format. Will be resized to maximum side of 224px.\n",
        "*   **Sentence**: Max token length 512."
      ],
      "metadata": {
        "id": "tq-JJr02OcUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# image formatting\n",
        "from PIL import Image\n",
        "img_path = \"/content/random_person.jpg\"\n",
        "img = Image.open(img_path)\n",
        "\n",
        "# text\n",
        "text = \"Top 10 Smartest People Ever\""
      ],
      "metadata": {
        "id": "0qhCZ9edPonQ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run Multimodal Bias Analysis\n",
        "\n",
        "Pass a string, and a PIL image into the `.analyze()` method."
      ],
      "metadata": {
        "id": "_5RwO-NsR2Ge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = multimodal_pipeline.analyze(text, img)"
      ],
      "metadata": {
        "id": "qoHEX02ZSF65"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example Output"
      ],
      "metadata": {
        "id": "OmRkDFtpSLjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)\n",
        "print(\"\\nLabel: \", result['label'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xL5CyvRSMuS",
        "outputId": "993e91df-7e03-4096-d82d-cc782f52faa8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': 'Top 10 Smartest People Ever', 'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1200x1499 at 0x7A82D0295360>, 'prob': 0.5121262669563293, 'label': 'Biased'}\n",
            "\n",
            "Label:  Biased\n"
          ]
        }
      ]
    }
  ]
}